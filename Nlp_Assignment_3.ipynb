{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Nlp_Assignment_3.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dKGPtt2WDaO",
        "outputId": "f498c9d4-8593-4eb3-aaba-e1113e9f6a73"
      },
      "source": [
        "!pip install wget\n",
        "\n",
        "import wget\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp37-none-any.whl size=9681 sha256=1c60056f9fc8410c27591240ba0b67d8e7cc4c089e703469a61d80606278a44a\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Zl1g2L8UWdal",
        "outputId": "47e67d0f-9e16-4510-847d-4af1544571df"
      },
      "source": [
        "wget.download('https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/train.en', 'train_en.txt')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'train_en.txt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "H6GCR17nWDaY",
        "outputId": "b7c40966-7c36-47ff-b419-89e9d8830897"
      },
      "source": [
        "wget.download('https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/train.vi', 'train_de.txt')\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'train_de.txt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "PLDsIl-DW803",
        "outputId": "c5c23cbd-586c-46eb-9607-563667cc3b67"
      },
      "source": [
        "wget.download('https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/tst2012.en', 'test_en.txt')\r\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'test_en.txt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "oS_TvSmlW-4S",
        "outputId": "c6dd83d8-f4c4-4f79-a163-571d97740fb2"
      },
      "source": [
        "wget.download('https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/tst2012.vi', 'test_de.txt')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'test_de.txt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nscU1ylcWDaZ"
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense\n",
        "import numpy as np\n",
        "\n",
        "batch_size = 64  \n",
        "epochs = 25  \n",
        "latent_dim = 256  \n",
        "num_samples = 1000 \n",
        "\n",
        "train_en = './train_en.txt'\n",
        "train_vi = './train_de.txt'\n",
        "\n",
        "test_en = './test_en.txt'\n",
        "test_vi = './test_de.txt'"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZFzF2OqWDab"
      },
      "source": [
        "input_characters = set()\n",
        "target_characters = set()"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-NFyv79WDac"
      },
      "source": [
        "\n",
        "with open(train_en, 'r', encoding='utf-8') as f:\n",
        "    input_text = f.read().split('\\n')"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwN58oixWDac"
      },
      "source": [
        "with open(train_vi, 'r', encoding='utf-8') as f:\n",
        "    target_text = f.read().split('\\n')"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYwgooQPWDae",
        "outputId": "5d145007-956f-4091-8fd8-0c66635fe7ff"
      },
      "source": [
        "# for text in input_t:\n",
        "#     input_text.append(text)\n",
        "len(target_text)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "133318"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ed0j29aqWDaf"
      },
      "source": [
        "input_texts = []\n",
        "target_texts =[]\n",
        "for i in range(min(len(target_text),num_samples)):\n",
        "    target_texts.append(target_text[i])\n",
        "    input_texts.append(input_text[i])"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsO7NA_sWDag",
        "outputId": "0c0e73c1-04fd-4f65-d0f3-286617b74a36"
      },
      "source": [
        "print(target_texts[:10])"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Khoa học đằng sau một tiêu đề về khí hậu', 'Trong 4 phút , chuyên gia hoá học khí quyển Rachel Pike giới thiệu sơ lược về những nỗ lực khoa học miệt mài đằng sau những tiêu đề táo bạo về biến đổi khí hậu , cùng với đoàn nghiên cứu của mình -- hàng ngàn người đã cống hiến cho dự án này -- một chuyến bay mạo hiểm qua rừng già để tìm kiếm thông tin về một phân tử then chốt .', 'Tôi muốn cho các bạn biết về sự to lớn của những nỗ lực khoa học đã góp phần làm nên các dòng tít bạn thường thấy trên báo .', 'Có những dòng trông như thế này khi bàn về biến đổi khí hậu , và như thế này khi nói về chất lượng không khí hay khói bụi .', 'Cả hai đều là một nhánh của cùng một lĩnh vực trong ngành khoa học khí quyển .', 'Các tiêu đề gần đây trông như thế này khi Ban Điều hành Biến đổi khí hậu Liên chính phủ , gọi tắt là IPCC đưa ra bài nghiên cứu của họ về hệ thống khí quyển .', 'Nghiên cứu được viết bởi 620 nhà khoa học từ 40 quốc gia khác nhau .', 'Họ viết gần 1000 trang về chủ đề này .', 'Và tất cả các trang đều được xem xét bởi 400 khoa học gia và nhà phê bình khác từ 113 quốc gia .', 'Đó là cả một cộng đồng lớn , lớn đến nỗi trên thực tế cuộc tụ hội hằng năm của chúng tôi là hội nghị khoa học &#91; tự nhiên &#93; lớn nhất thế giới .']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJ9UlJzyqrL_",
        "outputId": "8c9891a5-cf47-4097-880c-9ea6ab684e9a"
      },
      "source": [
        "input_texts[:10]"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Rachel Pike : The science behind a climate headline',\n",
              " 'In 4 minutes , atmospheric chemist Rachel Pike provides a glimpse of the massive scientific effort behind the bold headlines on climate change , with her team -- one of thousands who contributed -- taking a risky flight over the rainforest in pursuit of data on a key molecule .',\n",
              " 'I &apos;d like to talk to you today about the scale of the scientific effort that goes into making the headlines you see in the paper .',\n",
              " 'Headlines that look like this when they have to do with climate change , and headlines that look like this when they have to do with air quality or smog .',\n",
              " 'They are both two branches of the same field of atmospheric science .',\n",
              " 'Recently the headlines looked like this when the Intergovernmental Panel on Climate Change , or IPCC , put out their report on the state of understanding of the atmospheric system .',\n",
              " 'That report was written by 620 scientists from 40 countries .',\n",
              " 'They wrote almost a thousand pages on the topic .',\n",
              " 'And all of those pages were reviewed by another 400-plus scientists and reviewers , from 113 countries .',\n",
              " 'It &apos;s a big community . It &apos;s such a big community , in fact , that our annual gathering is the largest scientific meeting in the world .']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Bm2Ni8GWDag"
      },
      "source": [
        "i=-1\n",
        "for text in input_text:\n",
        "    i+=1\n",
        "    if i < num_samples:\n",
        "        for char in text:\n",
        "            \n",
        "            if char not in input_characters:\n",
        "                input_characters.add(char)\n",
        "    else:\n",
        "        break;\n",
        "    \n",
        "i=-1\n",
        "for text in target_text:\n",
        "    text = '\\t'+text+'\\n'\n",
        "    i+=1\n",
        "    if i < num_samples:\n",
        "        for char in text:\n",
        "            if char not in target_characters:\n",
        "                target_characters.add(char)\n",
        "    else:\n",
        "        break;"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PLuA1o-WDah",
        "outputId": "9f19a856-96df-4c68-9997-076bc5d260af"
      },
      "source": [
        "input_characters = sorted(list(input_characters))\n",
        "target_characters = sorted(list(target_characters))\n",
        "num_encoder_tokens = len(input_characters)\n",
        "num_decoder_tokens = len(target_characters)\n",
        "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
        "\n",
        "print('Number of samples:', len(input_texts))\n",
        "print('Number of unique input tokens:', num_encoder_tokens)\n",
        "print('Number of unique output tokens:', num_decoder_tokens)\n",
        "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
        "print('Max sequence length for outputs:', max_decoder_seq_length)\n",
        "target_characters"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples: 1000\n",
            "Number of unique input tokens: 79\n",
            "Number of unique output tokens: 159\n",
            "Max sequence length for inputs: 517\n",
            "Max sequence length for outputs: 612\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\t',\n",
              " '\\n',\n",
              " ' ',\n",
              " '!',\n",
              " '#',\n",
              " '$',\n",
              " '%',\n",
              " '&',\n",
              " ')',\n",
              " '+',\n",
              " ',',\n",
              " '-',\n",
              " '.',\n",
              " '/',\n",
              " '0',\n",
              " '1',\n",
              " '2',\n",
              " '3',\n",
              " '4',\n",
              " '5',\n",
              " '6',\n",
              " '7',\n",
              " '8',\n",
              " '9',\n",
              " ':',\n",
              " ';',\n",
              " '?',\n",
              " 'A',\n",
              " 'B',\n",
              " 'C',\n",
              " 'D',\n",
              " 'E',\n",
              " 'F',\n",
              " 'G',\n",
              " 'H',\n",
              " 'I',\n",
              " 'J',\n",
              " 'K',\n",
              " 'L',\n",
              " 'M',\n",
              " 'N',\n",
              " 'O',\n",
              " 'P',\n",
              " 'Q',\n",
              " 'R',\n",
              " 'S',\n",
              " 'T',\n",
              " 'U',\n",
              " 'V',\n",
              " 'W',\n",
              " 'X',\n",
              " 'Y',\n",
              " 'a',\n",
              " 'b',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'g',\n",
              " 'h',\n",
              " 'i',\n",
              " 'j',\n",
              " 'k',\n",
              " 'l',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'p',\n",
              " 'q',\n",
              " 'r',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " 'v',\n",
              " 'w',\n",
              " 'x',\n",
              " 'y',\n",
              " 'z',\n",
              " 'À',\n",
              " 'Á',\n",
              " 'Â',\n",
              " 'Í',\n",
              " 'Ô',\n",
              " 'Ý',\n",
              " 'à',\n",
              " 'á',\n",
              " 'â',\n",
              " 'ã',\n",
              " 'è',\n",
              " 'é',\n",
              " 'ê',\n",
              " 'ì',\n",
              " 'í',\n",
              " 'ñ',\n",
              " 'ò',\n",
              " 'ó',\n",
              " 'ô',\n",
              " 'õ',\n",
              " 'ö',\n",
              " 'ù',\n",
              " 'ú',\n",
              " 'ý',\n",
              " 'ă',\n",
              " 'Đ',\n",
              " 'đ',\n",
              " 'ĩ',\n",
              " 'ũ',\n",
              " 'ơ',\n",
              " 'ư',\n",
              " '̣',\n",
              " 'ạ',\n",
              " 'ả',\n",
              " 'ấ',\n",
              " 'ầ',\n",
              " 'ẩ',\n",
              " 'ẫ',\n",
              " 'ậ',\n",
              " 'ắ',\n",
              " 'ằ',\n",
              " 'ẳ',\n",
              " 'ẵ',\n",
              " 'ặ',\n",
              " 'ẹ',\n",
              " 'ẻ',\n",
              " 'ẽ',\n",
              " 'ế',\n",
              " 'ề',\n",
              " 'ể',\n",
              " 'ễ',\n",
              " 'ệ',\n",
              " 'ỉ',\n",
              " 'ị',\n",
              " 'ọ',\n",
              " 'ỏ',\n",
              " 'ố',\n",
              " 'Ồ',\n",
              " 'ồ',\n",
              " 'ổ',\n",
              " 'ỗ',\n",
              " 'ộ',\n",
              " 'ớ',\n",
              " 'ờ',\n",
              " 'Ở',\n",
              " 'ở',\n",
              " 'ỡ',\n",
              " 'ợ',\n",
              " 'ụ',\n",
              " 'ủ',\n",
              " 'ứ',\n",
              " 'Ừ',\n",
              " 'ừ',\n",
              " 'ử',\n",
              " 'ữ',\n",
              " 'ự',\n",
              " 'ỳ',\n",
              " 'ỵ',\n",
              " 'ỷ',\n",
              " 'ỹ',\n",
              " '—']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xNeICNlWDal",
        "outputId": "27136164-49f5-4adb-aa5b-9dde70ea149a"
      },
      "source": [
        "for text in input_texts[:10]:\n",
        "    print(len(text))"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "51\n",
            "278\n",
            "135\n",
            "154\n",
            "69\n",
            "181\n",
            "61\n",
            "49\n",
            "104\n",
            "147\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N753sMwwWDal",
        "outputId": "4d65cc52-1dc3-4e80-e6b8-5481665189f2"
      },
      "source": [
        "input_token_index = dict(\n",
        "    [(char, i) for i, char in enumerate(input_characters)])\n",
        "target_token_index = dict(\n",
        "    [(char, i) for i, char in enumerate(target_characters)])\n",
        "\n",
        "input_token_index"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{' ': 0,\n",
              " '!': 1,\n",
              " '#': 2,\n",
              " '&': 3,\n",
              " ')': 4,\n",
              " '+': 5,\n",
              " ',': 6,\n",
              " '-': 7,\n",
              " '.': 8,\n",
              " '/': 9,\n",
              " '0': 10,\n",
              " '1': 11,\n",
              " '2': 12,\n",
              " '3': 13,\n",
              " '4': 14,\n",
              " '5': 15,\n",
              " '6': 16,\n",
              " '7': 17,\n",
              " '8': 18,\n",
              " '9': 19,\n",
              " ':': 20,\n",
              " ';': 21,\n",
              " '?': 22,\n",
              " 'A': 23,\n",
              " 'B': 24,\n",
              " 'C': 25,\n",
              " 'D': 26,\n",
              " 'E': 27,\n",
              " 'F': 28,\n",
              " 'G': 29,\n",
              " 'H': 30,\n",
              " 'I': 31,\n",
              " 'J': 32,\n",
              " 'K': 33,\n",
              " 'L': 34,\n",
              " 'M': 35,\n",
              " 'N': 36,\n",
              " 'O': 37,\n",
              " 'P': 38,\n",
              " 'Q': 39,\n",
              " 'R': 40,\n",
              " 'S': 41,\n",
              " 'T': 42,\n",
              " 'U': 43,\n",
              " 'V': 44,\n",
              " 'W': 45,\n",
              " 'X': 46,\n",
              " 'Y': 47,\n",
              " 'a': 48,\n",
              " 'b': 49,\n",
              " 'c': 50,\n",
              " 'd': 51,\n",
              " 'e': 52,\n",
              " 'f': 53,\n",
              " 'g': 54,\n",
              " 'h': 55,\n",
              " 'i': 56,\n",
              " 'j': 57,\n",
              " 'k': 58,\n",
              " 'l': 59,\n",
              " 'm': 60,\n",
              " 'n': 61,\n",
              " 'o': 62,\n",
              " 'p': 63,\n",
              " 'q': 64,\n",
              " 'r': 65,\n",
              " 's': 66,\n",
              " 't': 67,\n",
              " 'u': 68,\n",
              " 'v': 69,\n",
              " 'w': 70,\n",
              " 'x': 71,\n",
              " 'y': 72,\n",
              " 'z': 73,\n",
              " 'ê': 74,\n",
              " 'ñ': 75,\n",
              " 'ö': 76,\n",
              " '—': 77,\n",
              " '…': 78}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pgPWI36WDam",
        "outputId": "64d3ce51-1093-4382-b62b-eae6cbce7426"
      },
      "source": [
        "encoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
        "    dtype='float32')\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')\n",
        "\n",
        "encoder_input_data.shape\n"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 517, 79)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_1wGmB-WDam",
        "outputId": "688f26f7-4be3-415e-cb54-21fa918fe837"
      },
      "source": [
        "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        encoder_input_data[i, t, input_token_index[char]] = 1\n",
        "    encoder_input_data[i, t + 1:, input_token_index[' ']] = 1.\n",
        "    for t, char in enumerate(target_text):\n",
        "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
        "        if t > 0:\n",
        "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n",
        "    decoder_input_data[i, t + 1:, target_token_index[' ']] = 1.\n",
        "    decoder_target_data[i, t:, target_token_index[' ']] = 1.\n",
        "    \n",
        "encoder_input_data\n"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [1., 0., 0., ..., 0., 0., 0.],\n",
              "        [1., 0., 0., ..., 0., 0., 0.],\n",
              "        [1., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [1., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [1., 0., 0., ..., 0., 0., 0.],\n",
              "        [1., 0., 0., ..., 0., 0., 0.],\n",
              "        [1., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [1., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [1., 0., 0., ..., 0., 0., 0.],\n",
              "        [1., 0., 0., ..., 0., 0., 0.],\n",
              "        [1., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [1., 0., 0., ..., 0., 0., 0.],\n",
              "        [1., 0., 0., ..., 0., 0., 0.],\n",
              "        [1., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [1., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [1., 0., 0., ..., 0., 0., 0.],\n",
              "        [1., 0., 0., ..., 0., 0., 0.],\n",
              "        [1., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [1., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [1., 0., 0., ..., 0., 0., 0.],\n",
              "        [1., 0., 0., ..., 0., 0., 0.],\n",
              "        [1., 0., 0., ..., 0., 0., 0.]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYEXPwCWWDan",
        "outputId": "0fa857da-ca2b-43cb-cbbb-b6cd6d454854"
      },
      "source": [
        "# Define an input sequence and process it.\n",
        "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
        "encoder = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "# We discard `encoder_outputs` and only keep the states.\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
        "# We set up our decoder to return full output sequences,\n",
        "# and to return internal states as well. We don't use the\n",
        "# return states in the training model, but we will use them in inference.\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
        "                                     initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "# Run training\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_split=0.2)\n",
        "# Save model\n",
        "model.save('s2s.h5')\n",
        "\n"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "13/13 [==============================] - 85s 6s/step - loss: 2.5127 - accuracy: 0.6810 - val_loss: 0.8016 - val_accuracy: 0.8695\n",
            "Epoch 2/25\n",
            "13/13 [==============================] - 80s 6s/step - loss: 0.6682 - accuracy: 0.8868 - val_loss: 0.7234 - val_accuracy: 0.8699\n",
            "Epoch 3/25\n",
            "13/13 [==============================] - 80s 6s/step - loss: 0.6172 - accuracy: 0.8896 - val_loss: 0.7045 - val_accuracy: 0.8699\n",
            "Epoch 4/25\n",
            "13/13 [==============================] - 83s 6s/step - loss: 0.6120 - accuracy: 0.8855 - val_loss: 0.6984 - val_accuracy: 0.8699\n",
            "Epoch 5/25\n",
            "13/13 [==============================] - 84s 6s/step - loss: 0.6188 - accuracy: 0.8848 - val_loss: 0.6674 - val_accuracy: 0.8699\n",
            "Epoch 6/25\n",
            "13/13 [==============================] - 81s 6s/step - loss: 0.5903 - accuracy: 0.8902 - val_loss: 0.6817 - val_accuracy: 0.8699\n",
            "Epoch 7/25\n",
            "13/13 [==============================] - 81s 6s/step - loss: 0.5957 - accuracy: 0.8881 - val_loss: 0.6598 - val_accuracy: 0.8699\n",
            "Epoch 8/25\n",
            "13/13 [==============================] - 90s 7s/step - loss: 0.5743 - accuracy: 0.8884 - val_loss: 0.6942 - val_accuracy: 0.8699\n",
            "Epoch 9/25\n",
            "13/13 [==============================] - 82s 6s/step - loss: 0.5804 - accuracy: 0.8854 - val_loss: 0.6502 - val_accuracy: 0.8699\n",
            "Epoch 10/25\n",
            "13/13 [==============================] - 81s 6s/step - loss: 0.5828 - accuracy: 0.8870 - val_loss: 0.6059 - val_accuracy: 0.8699\n",
            "Epoch 11/25\n",
            "13/13 [==============================] - 80s 6s/step - loss: 0.6102 - accuracy: 0.8863 - val_loss: 0.5907 - val_accuracy: 0.8699\n",
            "Epoch 12/25\n",
            "13/13 [==============================] - 80s 6s/step - loss: 0.5422 - accuracy: 0.8887 - val_loss: 0.5973 - val_accuracy: 0.8699\n",
            "Epoch 13/25\n",
            "13/13 [==============================] - 80s 6s/step - loss: 0.5188 - accuracy: 0.8853 - val_loss: 0.5718 - val_accuracy: 0.8699\n",
            "Epoch 14/25\n",
            "13/13 [==============================] - 80s 6s/step - loss: 0.5763 - accuracy: 0.8875 - val_loss: 0.5589 - val_accuracy: 0.8699\n",
            "Epoch 15/25\n",
            "13/13 [==============================] - 81s 6s/step - loss: 0.4829 - accuracy: 0.8875 - val_loss: 0.5448 - val_accuracy: 0.8702\n",
            "Epoch 16/25\n",
            "13/13 [==============================] - 80s 6s/step - loss: 0.5006 - accuracy: 0.8877 - val_loss: 0.5584 - val_accuracy: 0.8708\n",
            "Epoch 17/25\n",
            "13/13 [==============================] - 80s 6s/step - loss: 0.4640 - accuracy: 0.8920 - val_loss: 0.5272 - val_accuracy: 0.8702\n",
            "Epoch 18/25\n",
            "13/13 [==============================] - 80s 6s/step - loss: 0.4522 - accuracy: 0.8929 - val_loss: 0.5079 - val_accuracy: 0.8808\n",
            "Epoch 19/25\n",
            "13/13 [==============================] - 85s 7s/step - loss: 0.5069 - accuracy: 0.8981 - val_loss: 0.5009 - val_accuracy: 0.8760\n",
            "Epoch 20/25\n",
            "13/13 [==============================] - 82s 6s/step - loss: 0.4361 - accuracy: 0.8931 - val_loss: 0.4814 - val_accuracy: 0.8811\n",
            "Epoch 21/25\n",
            "13/13 [==============================] - 79s 6s/step - loss: 0.4153 - accuracy: 0.8992 - val_loss: 0.4678 - val_accuracy: 0.8824\n",
            "Epoch 22/25\n",
            "13/13 [==============================] - 80s 6s/step - loss: 0.4124 - accuracy: 0.8992 - val_loss: 0.4583 - val_accuracy: 0.8833\n",
            "Epoch 23/25\n",
            "13/13 [==============================] - 81s 6s/step - loss: 0.4048 - accuracy: 0.9014 - val_loss: 0.4395 - val_accuracy: 0.8930\n",
            "Epoch 24/25\n",
            "13/13 [==============================] - 80s 6s/step - loss: 0.3745 - accuracy: 0.9080 - val_loss: 0.4328 - val_accuracy: 0.8916\n",
            "Epoch 25/25\n",
            "13/13 [==============================] - 81s 6s/step - loss: 0.4800 - accuracy: 0.9042 - val_loss: 0.4229 - val_accuracy: 0.8955\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BjQbuO-AWDan",
        "outputId": "ee130eac-6cfe-42dc-b6cd-bbb28f62a39b"
      },
      "source": [
        "# Define sampling models\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(\n",
        "    decoder_inputs, initial_state=decoder_states_inputs)\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs] + decoder_states)\n",
        "\n",
        "# Reverse-lookup token index to decode sequences back to\n",
        "# something readable.\n",
        "reverse_input_char_index = dict(\n",
        "    (i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict(\n",
        "    (i, char) for char, i in target_token_index.items())\n",
        "\n",
        "\n",
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict(\n",
        "            [target_seq] + states_value)\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if (sampled_char == '\\n' or\n",
        "           len(decoded_sentence) > max_decoder_seq_length):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "        target_seq[0, 0, sampled_token_index] = 1.\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence\n",
        "\n",
        "\n",
        "for seq_index in range(100):\n",
        "    # Take one sequence (part of the training set)\n",
        "    # for trying out decoding.\n",
        "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print('-')\n",
        "    print('Input sentence:', input_texts[seq_index])\n",
        "    print('Decoded sentence:', decoded_sentence)\n",
        "    "
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-\n",
            "Input sentence: Rachel Pike : The science behind a climate headline\n",
            "Decoded sentence: h ng thi thi ng thi thi nh n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
            "-\n",
            "Input sentence: In 4 minutes , atmospheric chemist Rachel Pike provides a glimpse of the massive scientific effort behind the bold headlines on climate change , with her team -- one of thousands who contributed -- taking a risky flight over the rainforest in pursuit of data on a key molecule .\n",
            "Decoded sentence: h ng thi thi ng thi thi nh n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
            "-\n",
            "Input sentence: I &apos;d like to talk to you today about the scale of the scientific effort that goes into making the headlines you see in the paper .\n",
            "Decoded sentence: h ng thi thi ng thi thi nh n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
            "-\n",
            "Input sentence: Headlines that look like this when they have to do with climate change , and headlines that look like this when they have to do with air quality or smog .\n",
            "Decoded sentence: h ng thi thi ng thi thi nh n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
            "-\n",
            "Input sentence: They are both two branches of the same field of atmospheric science .\n",
            "Decoded sentence: h ng thi thi ng thi thi nh n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
            "-\n",
            "Input sentence: Recently the headlines looked like this when the Intergovernmental Panel on Climate Change , or IPCC , put out their report on the state of understanding of the atmospheric system .\n",
            "Decoded sentence: h ng thi thi ng thi thi nh n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
            "-\n",
            "Input sentence: That report was written by 620 scientists from 40 countries .\n",
            "Decoded sentence: h ng thi thi ng thi thi nh n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
            "-\n",
            "Input sentence: They wrote almost a thousand pages on the topic .\n",
            "Decoded sentence: h ng thi thi ng thi thi nh n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
            "-\n",
            "Input sentence: And all of those pages were reviewed by another 400-plus scientists and reviewers , from 113 countries .\n",
            "Decoded sentence: h ng thi thi ng thi thi nh n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
            "-\n",
            "Input sentence: It &apos;s a big community . It &apos;s such a big community , in fact , that our annual gathering is the largest scientific meeting in the world .\n",
            "Decoded sentence: h ng thi thi ng thi thi nh n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
            "-\n",
            "Input sentence: Over 15,000 scientists go to San Francisco every year for that .\n",
            "Decoded sentence: h ng thi thi ng thi thi nh n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
            "-\n",
            "Input sentence: And every one of those scientists is in a research group , and every research group studies a wide variety of topics .\n",
            "Decoded sentence: h ng thi thi ng thi thi nh n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
            "-\n",
            "Input sentence: For us at Cambridge , it &apos;s as varied as the El Niño oscillation , which affects weather and climate , to the assimilation of satellite data , to emissions from crops that produce biofuels , which is what I happen to study .\n",
            "Decoded sentence: h ng thi thi ng thi thi nh n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-100-2bfaf8a906f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m# for trying out decoding.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0minput_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_input_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseq_index\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mseq_index\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0mdecoded_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Input sentence:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_texts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseq_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-100-2bfaf8a906f5>\u001b[0m in \u001b[0;36mdecode_sequence\u001b[0;34m(input_seq)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstop_condition\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         output_tokens, h, c = decoder_model.predict(\n\u001b[0;32m---> 46\u001b[0;31m             [target_seq] + states_value)\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;31m# Sample a token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1627\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1629\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GIk3OOaAbVt"
      },
      "source": [
        "Since the model is trained on just 1k sentences so the accuracy isn't that great. \r\n",
        "\r\n",
        "Note : There is no error encountered its keyboard interrupt to stop the execution\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUwsodLrn0p1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}